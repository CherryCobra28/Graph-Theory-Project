\documentclass{article}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage[style=authoryear-ibid,backend=biber]{biblatex}
\title{Structural Differences Between Random Graphs and Small World, Scale-Free Graphs }
\date{08/02/2023}
\author{Thomas Draycott}
\addbibresource{references.bib}
\graphicspath{ {./images/} }
\begin{document}
    \maketitle
    \pagenumbering{arabic}
    \newpage
    \tableofcontents
    \newpage
    \begin{abstract}
        TO DO LAST
    \end{abstract}
    \section{Introduction}
    This project seeks to investigate the structural differences between random graphs and small-world, scale-free graphs and in paticular Albert-Barabási graphs.\\
    Then later we will use a SIRD model as a vehicle to explore whether these structural differences have an effect on random processes,  while traditionally a project that contains an SIRD model would focus on the model as its core concept we will only use it as a simple lens to investigate the differences between graph structures therefore little time will be afforded to the mathematics behind the SIRD simulation, only how it computes on our graphs.\\
    Random graphs were chosen as the comparison as by the fact they are random they are free of overarching structures that are present in other types of graph.\\
    The motivation for this project stems from my deep interest in graph theory and with the recent COVID-19 pandemic I wanted to explore whether how the way populations internally structured lead to a significant difference in the spread of disease.
    \section{Literature Review}
        \subsection{Graph Theory}
        Graph Theory is the study of networks where vertices are connected by edges (The word node and vertex will be used interchangeably and so will network and graph however graph will be used more for more abstract representations). We will be only focusing on simple graphs in this project and any graph mentioned can be assumed to be a simple graph. A strict definition of simple graphs is as follows \parencite{bender2010lists}: Let $G$ be a graph, $G$ is an ordered pair $G=(V,E)$ comprising $V$: a set of vertices and $E\subseteq \{\{x,y\} | x,y \in V \text{ and } x\neq y\}$: a set of edges which are unordered pairs of vertices.
        \subsection{Random Graphs}
        In 1959, Paul Erd\"{o}s and Alfr\'{e}d R\'{e}nyi published their paper 'On Random Graphs' \parencite{erd6s1959random} and independently Edgar Nelson Gilbert published his paper 'Random Graphs' \parencite{gilbert1959random}. Both papers describe how to create a graph using probabilities which became a very useful tool for solving problems in graph theory particularly problems in which they wished to prove the existence of certain graphs held various properties or to provide a strong definition for what it meant for a property to hold for almost all graphs. However, Erd\"{o}s' and Gilbert's models differed in how they worked. The Erd\"{o}s-R\'{e}yi model works as follows to generate a random graph $G(n,M)$ where $n$ is the number of nodes in the graph and $M$ is the total number of edges to be added, randomly pick $M$ pairs of vertices from the set of all combinations of two vertices, ignoring repeats and draw edges between them. In this model the average degree is easily calculated however it is rare that the number of edges will be so exact which brings on to the Gilbert model. For the Gilbert Model we define the random graph $G$ as such $G(n,p)$ where $n$ is the total number of nodes and $p$ is the probability of joining to vertices together and works as follows: draw $n$ nodes for the graph, select a vertex pair, generate a random number between $0$ and $1$, if the number exceeds $p$ draw en edge between those two vertices, repeat for all vertex pairs once. For the rest of this paper we will use 'random graph' to refer to Gilbert model random graphs as they better represent real networks because the number of edges is not fixed. 
        \subsection{Small World Graphs}
        In May 1967 Professor of Psychology at the Graduate School and University Center of the City University of New York, Stanley Milgram ran an experiment to see if a person living
        in Omaha, Nebraska could get a parcel to a stockbroker in Boston, Massachusetts \parencite{milgram1967small}. In his experiment he found the average path length to reach the stockbroker was 5.5, which created the term
        six degrees of separation (however Milgram's experiment had flaws which puts the exact number into doubt). This idea of having such a small average path length for such numerous nodes is a hallmark of a small world graph.\\
        A Small world graph is formally defined by the following property: $L\propto\log{N}$ where $L$ is the average shortest path length of the network and $N$ is the total number of nodes \parencite{Watts1998}. Several models exist to generate small world graphs such as the Watts-Strogatz Model.

        \subsection{Scale Free Graphs}
        In networks that appear in the real world such as the internet and social groups, there exists nodes known as "hubs" (a node that has a  significantly higher degree then the average of the graph). This is an important property encapsulated in Scale-Free Graphs.\\ 
        Scale-free Graphs are formally defined by the following power law: $P(k) \sim  k^{-\gamma }$, $k$ is the degree of a vertex, $P(k)$ is the probability of a node having degree $k$ and $\gamma$ is a parameter determined by the graph typically $2<\gamma<3$ \parencite{onnela2007structure}.

        \subsection{Barabasi-Albert Model}
        In 1999, Albert-László Barabási and Réka Albert developed the Albert-Barabási Model which generates small world, scale free graphs by a process of preferential attachment \parencite{barabasi1999emergence}. The model works as such: define two parameters $n$ (The number nodes the graph at the end of the process will have) and $e$ (the number of edges added for each new node) take a seed graph, add one new node to the graph, using preferential attachment add $e$ edges from the new node to nodes on the seed graph, continue till there are $n$ nodes on the graph.\\
        Preferential attachment describes a 'rich get richer effect' that is the higher the degree of the node the more likely it will gain a new edge, the following formula describes it $\prod (k_{i}) = \frac{k_{i}}{\sum_{j} {k_{j}}}$ where $k_{i}$ is the degree of node $i$. 
        \subsection{SIRD Model}
        SIRD stands for Susceptible, Infected, Recovered and Dead which is the states each individual in the model can take. There are many was of implementing a model like this such as a virus having specific infection 'power' and mortality rates or having the infection be determined entirely by the individual.
    \section{Mathematical Methods}
        \subsection{Graph Theory}
            \subsubsection{Degrees}
            We will provide some key definitions and results from Graph Theory which will be useful for the further topics \parencite{barabasi2013network}.\\
            Degree: The number of edges attached to a node (Commonly written as $k_i$ denoting the degree $k$ of node $i$). We can also calculate the number of edges $L$ of a graph from the sum of the degrees that is: 
            \begin{align*}
                L=\frac{1}{2}\sum_{i=1}^{N} k_{i}
            \end{align*}
            Average degree:
            \begin{align*}
                \langle k \rangle = \frac{1}{N} \sum_{i=1}^{N}k_{i} = \frac{2L}{N}
            \end{align*}
            ($\langle k \rangle$ and $\overline{k}$ will be used interchangeably, but the first will be more common)
            Degree distribution: The probability distribution of the degrees of graph will be very relevant in the later sections, so we will define it here as $p_k$ which is the probability a node has degree $k$.
            \begin{align*}
                &\text{As $p_k$ is a probability we must normalize it with the following condition:}\\
                &\sum_{k=1}^{\infty}p_{k} = 1\\
                &\text{For a network with $N$ nodes where $N_k$ is the number of nodes with degree $k$}\\
                &p_{k} = \frac{N_k}{N}\\
                &\text{With this we can redefine $\langle k \rangle$ as:}\\
                &\langle k \rangle = \sum_{k=0}^{\infty}kp_{k}
            \end{align*}
        \subsubsection{Adjacency Matrix}
            Graphs can also be represented by adjacency matrices. We define the matrix $A$, entry $A_{i,j} = 1$ if there is an edge between node $i$ and node $j$ else $A_{i,j} = 0$. For an undirected graph $A$ is symmetrical.\\
        \subsubsection{$L_{\text{max}}$}
            The total number of edges $L$ for a graph is bounded by $L_{\text{max}}$ and $L=0$
            \begin{align*}
                L_{\text{max}} =  \frac{N(N-1)}{2}\\
            \end{align*}
            We can see this by the most edges a simple graph can have is if it is a complete graph and complete graphs have $\frac{N(N-1)}{2}$ therefore a non-complete graph must have fewer edges\\
            Most real networks are sparse that is $L\ll L_{\text{max}}$\\
        \subsubsection{Paths}
        A path is an ordered list of nodes describing a walk from each node to another. A Path length is the number of nodes contained in a path. The shortest path is the path between node $i$ and node $j$ with the smallest possible path length and is usually denoted as $d_{i,j}$ or just $d$. The diameter of a graph is defined as the longest shortest path of a graph and is denoted as $d_{\text{max}}$.\\
        Average shortest path length is defined as the average of the shortest paths between all pairs of nodes and is denoted as $\langle d \rangle$ and is calculated as such:
        \begin{align*}
            &\langle d \rangle = \frac{1}{N(N-1)}\sum_{i,j=1,N | i\neq j}d_{i,j}
        \end{align*}

        \subsubsection{Clustering Coefficient}
            The clustering coefficient captures the degree to which the neighbors of a given node link to each other \parencite{barabasi2013network}. For a node $i$ with degree $k_{i}$ the local clustering coefficient is defined as \parencite{Watts1998}.
            \begin{align*}
                &C_{i} = \frac{2L_{i}}{k_{i}(k_{i}-1)} 
                &\text{Where $L_{i}$ is the number of links between the $k_i$ neighbors of node $i$. $C_{i}$ is between $0$ and $1$}
            \end{align*}
            $C_i$ represents the proportion that the neighbors of node $i$ are connected\\
            We can define the average clustering coefficient of a graph as such:
            \begin{align*}
                \langle C \rangle = \frac{1}{N}\sum_{i=1}^{N}C_{i}
            \end{align*}
            $\langle C \rangle$ can also be interpreted as the probability two neighbors of a randomly selected node link to each other


        \subsection{Random Graphs}
        For a random graph $G(N,p)$ we will define some key behaviors and values.
            \subsubsection{Number of Edges}
            We can begin by defining the probability of a random graph having exactly $L$ edges:
            Firstly there are $\frac{N(N-1)}{2}$ pairs of nodes to which we can draw edges between, then the probability that $L$ of the attempts to connect the $\frac{N(N-1)}{2}$ pairs of nodes have resulted in an edge is $p^L$, then the probability that the remaining  $\frac{N(N-1)}{2} -L$ attempts have not resulted in an edge is $(1-p)^{\frac{N(N-1)}{2} -L}$ and finally there is $\binom{\frac{N(N-1)}{2}}{L}$ different ways to draw $L$ edges between $\frac{N(N-1)}{2}$ pairs of nodes. Taking the product of these factors we gain:
            \begin{align*}
                p_{L} = \binom{\frac{N(N-1)}{2}}{L}p^L(1-p)^{\frac{N(N-1)}{2} -L}
            \end{align*}
            Which is clearly a binomial distribution therefore the mean number of edges $\langle L \rangle$ is given by $np$ which for this example is equal to $p\frac{N(N-1)}{2}$. We also obtain the average degree of the random graph:
            \begin{align*}
                \langle k \rangle = \frac{2 \langle L \rangle}{N} = p(N-1)
            \end{align*}
            Note that $N-1$ is the maximum degree a node can have in this graph.
            \subsubsection{Degree distribution}
            Similarly to the case of edges above we can construct a binomial distribution for the degrees of the random graph. The probability a randomly chosen node will have degree $k$ will be again a product of three terms defined as follows: The probability the node has $k$ edges is $p^k$. The probability the remaining $N-1-k$ edges are missing is $(1-p)^{N-1-k}$. And the number of ways a node can have degree $k$ from degree $N-1$ is $\binom{N-1}{k}$ thus.
            \begin{align*}
                p_{k} = \binom{N-1}{k}p^k(1-p)^{N-1-k}
            \end{align*}  
            Again using the properties of the binomial distribution we see that the average degree is $p(N-1)$ and the variance is $p(N-1)(1-p)$
            \subsubsection{The Poisson Approximation}
            Most real networks are sparse that is $\langle k \rangle \ll N$ in these cases the degree distribution is well approximated with:
            \begin{align*}
                p_{k} = e^{-\langle k \rangle}\frac{{\langle k \rangle}^k}{k!}
            \end{align*}
            Using this approximation can be very useful for a number of reasons, firstly the variance and other key characteristics only depend on a single value that being $\langle k \rangle$. It also suggests an interesting detail, because it does not rely on $N$, the degree distributions of graphs of varying sizes, but the small average degree are in fact identical to each other. It also makes further calculations easier however it must be firmly stated that the approximation only holds for sparse graphs and typically small graphs (those where $N$ is less than 1000) are not sparse enough for this approximation to hold. We will use this approximation later but the requirements for it to hold must be remembered.
        \subsection{Small World Graphs}
            \subsubsection{Diameter}
            Considering a random network with an average degree $\langle k \rangle$, a node will have on average \parencite{barabasi2013network}:\\
            $\langle k \rangle$ nodes at distance 1 ($d=1$)\\
            $\langle k \rangle^2$ nodes at distance 2 ($d=2$)\\
            $\langle k \rangle^3$ nodes at distance 3 ($d=3$)\\
            ...\\
            $\langle k \rangle^d$ nodes at distance d ($d$)\\
            Precisely the expected number of nodes up to distance $d$ from our starting node is $N(d) = 1+\langle k \rangle+\langle k \rangle^2+\langle k \rangle^3+...+\langle k \rangle^d$ which is equal to $\frac{\langle k \rangle^{d+1}-1}{\langle k \rangle -1}$. We have to set an upper bound on $N(d)$ as obviously cannot be greater than $N$, so we set $N(d_{\text{max}}) \approx N$. Assuming $\langle k \rangle \gg 1$ we can disregard the $(-1)$ term in the numerator and denominator to obtain: $\langle k \rangle^{d_{\text{max}}} \approx N$ therefore the diameter of the network follows $d_{\text{max}} \approx \frac{\log{N}}{\log{\langle k \rangle}}$. Here we have the definition of the small world effect, the previous equation describes the scaling of the diameter however the average shortest path length $\langle d \rangle$ is better approximated by the previous equation as the diameter is easily increased by rare extremely long shortest path lengths. Generally $\log{N} \ll N$ which suggest the average shortest path length is orders pf magnitude smaller than the size of the network which gives the definition of small: $\langle d \rangle \propto \log{N}$, with the $\frac{1}{\langle k \rangle}$ term correcting for denser networks having a smaller distance between nodes.
            \subsubsection{Clustering Coefficient}
            We define $C_i$ as the local clustering coefficient of node $i$. To calculate the local clustering coefficient we need the exppected number of edges $E_i$ between the nodes $k_i$ neighbours. In a random graph the probability that two of $i$'sneighbours link to each other is $p$.\\ There are $\frac{k_{i}(k_{i}-1)}{2}$ possible edges between $k_i$ neighbours of node $i$, the expected value of $E_i$ is:
            \begin{align*}
                &\langle E_i \rangle = p\frac{k_{i}(k_{i}-1)}{2}\\
                &\text{Therefore the localclustering coefficient of a random network is}\\
                &C_i = \frac{2\langle E_i \rangle}{k_{i}(k_{i}-1)} = p = \frac{\langle k \rangle}{N}
            \end{align*} 
            From we glean this, for a fixed average degree, the larger the network the smaller a nodes clustering is and the local clustering coefficient of a node is independent of the nodes degree.
        \subsection{Scale-Free Graphs}
        Scale-Free Graphs follow a power law, that is $p_{k} \sim k^{-\gamma}$ where $p_{k}$ is the probability of having degree $k$. We will now show the discrete formalism of the power law \parencite{barabasi2013network}.
        \begin{proof}
            \begin{align*}
                &\text{Assuming: } k\in \mathbb{N}\\
                &p_{k} = Ck^{-\gamma} \text{ where C is a constant}\\
                &\text{C is determined by the normalization condition: }\\
                &\sum_{k = 1}^{\infty}p_{k} = 1\\
                &\text{Using line 2 we obtain}\\
                &C\sum_{k=1}^{\infty}k^{-\gamma} = 1\\
                &\text{Thus}\\
                &C = \frac{1}{\sum_{k=1}^{\infty}k^{-\gamma}} = \frac{1}{\zeta(\gamma)}\\
                &\text{Where $\zeta(s)$ is the Riemann Zeta Function}\\
                &\therefore p_{k}=\frac{k^{-\gamma}}{\zeta(\gamma)} &(4.1)
            \end{align*}
            Therefore the average degree of a scale-free graph is:
            \begin{align*}
                &\overline{k} = \sum_{k=1}^{\infty}kp_{k}\\
                &\therefore \overline{k} = \sum_{k=1}^{\infty}k\frac{k^{-\gamma}}{\zeta(\gamma)} &(4.2)\\
            \end{align*}
            We can also define a Continuum formalism for the power law distribution because for analytic calculations it is useful to let the degree k be any positive real number as follows \parencite{barabasi2013network}:
            \begin{align*}
                &\text{Assuming: } k\in \mathbb{R}^{+}\\
                &p(k) = Ck^{-\gamma}\\
                &\text{Using the normalization condition:}\\
                &\int_{k_{\text{min}}}^{\infty}p(k) \,dk = 1\\
                &\therefore C = \frac{1}{\int_{k_{\text{min}}}^{\infty}k^{-\gamma} \,dk} = (\gamma -1)k_{\text{min}}^{\gamma-1}\\
                &\therefore p(k) = (\gamma -1)k_{\text{min}}^{\gamma-1}k^{-\gamma}  &(4.3)\\
                &\text{Where $k_{\text{min}}$ is the smallest degree for which the power law holds.}\\
                &\text{Note only the integral of p(k) holds any precise interpretation in the continuum formalism}
            \end{align*}
        \end{proof}
        We would now like to calculate $k_{\text{max}}$ this represents the expected size of the largest hub in the network.
        \begin{align*}
            &\text{We assume in a network of $N$ nodes we expect at most one node in the $(k_{\text{max}},\infty)$ range such that}\\
            &\int_{k_{\text{max}}}^{\infty}p(k) \,dk = \frac{1}{N}\\
            &\text{Using result (4.3) we get the result:}\\
            &k_{\text{max}} = k_{\text{min}}N^{\frac{1}{\gamma -1}} &(4.4)\\
            &\text{See APPENDIX Proofs section Scale Free number 1 }
        \end{align*}
        This means that $k_{\text{max}}$ has a polynomial dependence on $N$, so there can be a order of magnitude difference between $k_{\text{min}}$ and $k_{\text{max}}$.\\
        We can extend this to talk about the 'moments' of the degree distribution with the following formula \parencite{papoulis2002probability}:\\
        \begin{align*}
            &\langle f(x) \rangle = \sum f(x)P(x)
        \end{align*}
        Applying this to degree distribution we gain the following, the $n^{th}$ moment is defined as:\\
        \begin{align*}
            &\langle k^n \rangle = \sum_{k_{\text{min}}}^{\infty}k^{n}p_{k} \approx \int_{k_{\text{min}}}^{\infty} k^{n}p(k)  \,dk \\
            &\text{Where $k_{\text{min}}$ is the smallest degree such that the distribution holds}
        \end{align*}
        Now the interpretation of these moments are important. $n=1$ gives us the mean degree. $n=2$ allows us to calculate the variance of the degree distribution via the formula: $\sigma^2 = \langle k^2 \rangle - \langle k\rangle ^2$. $n=3$ gives us the skewness of the degree distribution.
        Now we apply this to our scale-free graph to gain insights to its moments.
        \begin{align*}
            &\langle k^n \rangle = \int_{k_{\text{min}}}^{k_{\text{max}}}k^{n}p(k) \,dk = C\frac{k^{n-\gamma -1}_{\text{max}}-k^{n-\gamma -1}_{\text{min}}}{n-\gamma +1}\\
            &\text{Where $k_{\text{max}}$ is the largest hub in the network }\\
            &\text{A proof of the above integral will be in the APPENDIX Proofs section Scale Free number 2}
        \end{align*}
        Let us allow $k_{\text{min}}$ to stay fixed and to investigate the behavior of $\langle k^n \rangle$ we will take the limit as $k_\text{max} \to \infty$ doing, so we see that the values of $\langle k^n \rangle$ are dictated by the $n-\gamma -1$ term. If $n-\gamma -1 \leqslant 0$ then $k^{n-\gamma -1}_{\text{max}}$ will tend to $0$ as $k_\text{max}$ increases, therefore all moments that satisfy $n\leqslant \gamma-1$ are finite. Conversely, if  $n-\gamma -1 > 0$  then $\langle k^n \rangle$ goes to infinity as $k_\text{max} \to \infty$ so for all moments larger than $\gamma-1$ diverge.\\ 
        For most scale-free graphs $2<\gamma<3$ and thus as $N\to \infty$ the first moment $\langle k \rangle$ is finite but $\langle k^2 \rangle$ and $\langle k^3 \rangle$ will go to infinity. Thus, we can see wit the divergence of $\langle k^2 \rangle$ the variance (and standard deviation) can be arbitrarily large, if we picked a node at random we know very little about its degree. "Hence networks with $\gamma<3$ do not have a meaningful internal scale but are scale free" \parencite{barabasi2013network}. As an example to concrete this in his 1993 paper Barabási found the degree $k$ of a randomly chosen node int the WWW was $4.6 \pm 1546$ which shows that despite $\langle k^2 \rangle$ only diverges in the $N \to \infty$ limit that the standard deviation $\sigma \gg  \langle k \rangle$.\\
        The average shortest path length $\langle d \rangle$ depends on the network size $N$ and the degree exponent $\gamma$ described in the following formula \parencite{bollobas2004diameter}\parencite{cohen2003scale}:\\
        \begin{align*}
            &\langle d \rangle \sim
            \begin{cases}
                \text{const.} &\gamma =2\\
                \ln\ln N  &2<\gamma<3\\
                \frac{\ln N}{\ln\ln N}  &\gamma = 3\\
                \ln N  &\gamma>3
            \end{cases}
        \end{align*}
        Let us discuss the implication of the behaviors described above \parencite{barabasi2013network}:\\
        For $\gamma$ the degree of the largest hub $k_{\text{max}}$ grows linearly with network size $N$. Which forces the network into a 'hub and spoke' configuration where all the nodes are close together because they all connect to a central hub. The average shortest path length does not depend on $N$. This is known as an Anomalous regime\\
        For $2<\gamma<3$ the average shortest path length grows much slower than the $\ln N$ derived for random networks, this is referred to an ultra-small world regime \parencite{cohen2003scale}. The hubs massively reduce the average path length.\\
        For $\gamma =3$ Here the 2nd moment of the degree distribution now longer diverges, we regain the $\ln N$ dependence from the random networks but the $\ln\ln N$ shrinks the average path length under that of a similarly sized random networks.\\
        For $\gamma > 3$ At this point $\langle k^2 \rangle$ is finite and the average shortest path length follows the small world effect from random graphs. Hubs at this point are not sufficiently large to have an impact on the average shortest path length.
        (Note to expand on later large scale free graphs where $\gamma < 2$ do not exist as simple graphs, this may allow our assumption of $\gamma >1$)
        \subsection{Albert-Barabasi model}
        TODO
        \subsection{SIRD Model}
        TODO
    \section{Analysis}
        \subsection{Theoretical difference}
        TODO
        \subsection{Physical difference}
        TODO
        
        
    \section{Evaluation}
    TODO
    \section{APPENDIX}
        \subsection{Proofs}
            \subsubsection{Graph Theory}
            TODO
            \subsubsection{Random Graphs}
            TODO
            \subsubsection{Small World Graphs}
            TODO
            \subsubsection{Scale-Free Graphs}
            Proof 1: note is this assumption valid
            \begin{align*}
                &\int_{k_{\text{max}}}^{\infty} p(k) \,dk = \frac{1}{N}\\
                &\text{Result (4.3): } p(k) = (\gamma -1)k^{\gamma-1}_{\text{min}}k^{-\gamma}\\
                &\text{Note: $(\gamma -1)k^{\gamma-1}_{\text{min}}$ is a constant which we will call $C$}\\
                &\text{Thus}\\
                &C\int_{k_{\text{max}}}^{\infty}k^{-\gamma} \,dk  = \frac{1}{N}\\
                &C[\frac{1}{1-\gamma}k^{1-\gamma}]^{\infty}_{k_{\text{max}}} = \frac{1}{N}\\
                &\text{Assuming $\gamma>1$}\\
                &\lim_{k \to \infty} \frac{1}{1-\gamma}k^{1-\gamma}= 0\\
                &\therefore C\frac{{k^{1-\gamma}_{\text{max}}}}{\gamma -1} = \frac{1}{N}\\
                &(\gamma-1)k^{\gamma-1}_{\text{min}}\frac{{k^{1-\gamma}_{\text{max}}}}{\gamma -1} = \frac{1}{N}\\
                &k^{1-\gamma}_{\text{max}} = \frac{1}{Nk^{\gamma-1}_{\text{min}}}\\
                &k^{\gamma -1}_{\text{max}} = Nk^{\gamma-1}_{\text{min}}\\
                &k_{\text{max}} = (Nk^{\gamma-1}_{\text{min}})^{\frac{1}{\gamma-1}}\\
                &\therefore k_{\text{max}} = k_{\text{min}}N^{\frac{1}{\gamma-1}} \qed
            \end{align*}
            Proof 2:
            \begin{align*}
                &\langle k^n \rangle = \int_{k_{\text{min}}}^{k_{\text{max}}}k^{n}p(k) \,dk\\
                &\text{Result (4.3): } p(k) = (\gamma -1)k^{\gamma-1}_{\text{min}}k^{-\gamma}\\
                &\langle k^n \rangle = \int_{k_{\text{min}}}^{k_{\text{max}}} (\gamma-1)k^{-\gamma}_{\text{min}}k^{n}k^{-\gamma} \,dk \\
                &\text{Again $ (\gamma-1)k^{-\gamma}_{\text{min}}$ is a constant we will call $C$}\\
                &\langle k^n \rangle = C\int_{k_{\text{min}}}^{k_{\text{max}}}k^{n}k^{-\gamma} \,dk\\ 
                &\langle k^n \rangle = C\int_{k_{\text{min}}}^{k_{\text{max}}}k^{n-\gamma} \,dk\\
                &\langle k^n \rangle = C[\frac{1}{n-\gamma +1}k^{n-\gamma+1}]^{k_{\text{max}}}_{k_{\text{min}}}\\
                &\langle k^n \rangle = C\frac{k_{\text{max}}^{n-\gamma+1} -k_{\text{min}}^{n-\gamma+1}}{n-\gamma +1 }
            \end{align*}

        \subsection{Python}
        This project is written in the Python programming language as it is the language I am most familiar with and has very useful modules for graph analysis. All the code to create these graphs is completely doable without 3rd party libraries however as this project focuses on more complicated topics than just graph creation I will be using a 3rd party library to simplify creating graphs and manipulating them as detailed below.
        \subsection{Networkx}
        To begin we should explain the software that this project is based most heavily on. Networkx is a module for the Python programming language that allows for the creation and manipulation of graphs \parencite{SciPyProceedings_11}.
        \subsection{Creating Graphs}
        First we need to show how to create a graph using the software.\\
        \includegraphics[width=8cm]{images/add_nodes_add_edges.png}\\
        The above code does the following: it imports the Networkx package for us to use, creates a 'graph' object called G, creates nodes A, B, C, then adds two edges between A and B and B and C.\\
        However that is too cumbersome for normal use so the Networkx package provides functions such as:
        \begin{verbatim}networkx.complete_graph(5)\end{verbatim}
        to generate a complete graph with 5 nodes in one line, but we still have very fine control of the graph as in the first example.
        \subsection{Creating Random Graphs}
        To create a random graph on a piece of paper it is quite simple: Select $N$ nodes to add to the graph and $p$ probability, draw $N$ nodes on the paper, then go through every possible pair of nodes in the graph and draw an edge between them if when picking a random real number from [0,1] it is less than $p$. Networkx implements a function \verb|networkx.gnp_random_graph| to create a random graph using the following code:\\
        \begin{figure}[H]
            \includegraphics[width=8cm]{images/CreatingRandomGraphs.png}
            \caption{The Random Graph Function}
            \label{fig:RandomGraph1}
        \end{figure}
        Let us explain, the function takes $n$ (The total number of nodes) and $p$ (The probability of drawing an edge between a pair of nodes) as parameters. The \verb|itertools.combinations(range(n),2)| creates s list of every combination of 2 numbers up to $n$ i.e. (0,1), (0,2), (1,2) and so on, then to graph $G$ we add $n$ nodes, if $p = 0$ then there are 0 edges in the graph, so it stays empty and if $p =1$ then every node is attached to every other node, so it becomes a complete graph, if neither of those are true then we loop through all the possible combinations of nodes and choose a random number from $[0,1]$ and if that is less than $p$ we add an edge between those nodes.
        \subsection{Creating Barabasi-Albert Graphs}
        First let us describe how to create Barabasi-Albert Graphs on a piece of paper. To create a Barabasi-Albert Graph we must first start with a "seed" graph (An already drawn graph that we will grow using the Barabasi-Albert Model) then we will define two more parameters $n$ for the total number of nodes we want this new graph to have and $m$ the number of edges we will add each iteration of the model. The algorithm works in the following way: take your "seed" graph and assign each node on the graph a probability $p$ according to its degree $k$ using the formula $p(k_{i}) = \frac{k_{i}}{\sum_{j} {k_{j}}}$ we then randomly select $m$ unique nodes according to the probabilities calculated (this can be done by label each node 1 to n then write on a piece of paper that label for each node, then fold the paper a number of times proportional to its probability for example folding 0.2 twice but 0.2 five times then randomly choosing the papers), add 1 new node to the graph and draw an edge from this new node to each of the randomly preexisting nodes, repeat this until we have $n$ nodes on the graph.\\
        As Barabasi-Albert graphs are the main focus of this project we will now show how they are created in networkx. 
        \begin{figure}[H]
            \includegraphics[width=12cm]{images/BARABASI_FUNC.png}
            \caption{The Barabasi-Albert Graph Function}
            \label{fig:Barabasi-Albert function1}
        \end{figure}
        This is the Barabási-Albert function from Networkx. It takes 4 parameters, $n$,$m$, \verb|seed|, and \verb|initial_graph|. $n$ and $m$ are simply the same as explained above, \verb|seed| is for the random functions later so we can control the behavior,  \verb|initial_graph| is where we input our 'seed graph' for the model to build on (If no graph is provided then it uses a Star graph with $(m+1)$ nodes). The function then creates a list of nodes: \verb|repeated_nodes| where each node is repeated equal to its degree (A node with degree $5$ is repeated 5 times) then takes random samples from this list to create the preferential attachment then finally returns the Barabási-Albert graph. 
        
        \subsection{Gaining Information From Graphs}
        Methods in networkx allow us to extract key information from the graph objects such as \verb|G.number_of_edges| which returns the number of edges that are contained in graph $G$ or \verb|networkx.all_neighbors(G,n)| which returns all the neighbors of node $n$ in graph $G$.
            
    
    
\printbibliography
\end{document}